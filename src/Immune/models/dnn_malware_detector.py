"""Simple MLP for malware detection with training and evaluation."""

import logging
import time
from pathlib import Path
from typing import Any, Dict, List, Optional
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

logger = logging.getLogger(__name__)


class DNNMalwareDetector(nn.Module):
    """Simple fully connected MLP for malware detection."""

    def __init__(self, layers: Optional[List[int]] = None, dropout_rates: List[float] = None):
        super().__init__()

        if layers is None:
            layers = [700, 512, 512, 512, 1]
        
        if dropout_rates is None:
            dropout_rates = [0.5, 0.3, 0.2]
        
        self.layers = layers
        self.input_size = layers[0]
        self.dropout_rates = dropout_rates

        modules: List[nn.Module] = []

        # Hidden layers: Linear + ReLU + Dropout
        for i in range(len(layers) - 2):
            modules.append(nn.Linear(layers[i], layers[i + 1]))
            modules.append(nn.BatchNorm1d(layers[i + 1]))
            modules.append(nn.ReLU())
            if dropout_rates is not None and dropout_rates[i] > 0:
                modules.append(nn.Dropout(dropout_rates[i]))

        # Output layer
        modules.append(nn.Linear(layers[-2], layers[-1]))
        # modules.append(nn.Sigmoid())

        # Use Sequential so the module is callable
        self.network = nn.Sequential(*modules)

        logger.info(f"Initialized DNNMalwareDetector with layers: {layers}")
        logger.info(f"Network: {self.network}")
        logger.info(f"Total parameters: {sum(p.numel() for p in self.parameters()):,}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

    def predict(self, x: torch.Tensor, threshold: float = 0.5) -> torch.Tensor:
        with torch.no_grad():
            probabilities = self.forward(x)
            return (probabilities > threshold).float()

    def get_feature_importance(self, x: torch.Tensor) -> torch.Tensor:
        x.requires_grad_(True)
        output = self.forward(x)
        output.backward(torch.ones_like(output))
        importance = torch.abs(x.grad)
        return importance

    def save_model(self, filepath: Path) -> None:
        torch.save(
            {
                "model_state_dict": self.state_dict(),
                "layers": self.layers,
                "dropout_rates": self.dropout_rates,
            },
            filepath,
        )
        logger.info(f"Model saved to {filepath}")

    @classmethod
    def load_model(cls, filepath: Path, device: str = "cpu") -> "DNNMalwareDetector":
        checkpoint = torch.load(filepath, map_location="cpu")
        model = cls(layers=checkpoint["layers"], dropout_rates=checkpoint["dropout_rates"])
        model.load_state_dict(checkpoint["model_state_dict"])
        logger.info(f"Model loaded from {filepath}")
        model.to(device)
        return model


class MalwareDataset:
    """Dataset class for malware detection."""

    # from features.json
    def __init__(self, features: Dict[str, Dict[str, Any]], cut_off: int = None):
        v = features.values()
        if "features" in features and "labels" in features:
            self.features = torch.FloatTensor(features["features"])
            self.labels = torch.FloatTensor(features["labels"])
        elif "feature_array" in v[0] and "is_malware" in v[0]:
            self.features = torch.FloatTensor([feature["feature_array"] for feature in v])
            self.labels = torch.FloatTensor([feature["is_malware"] for feature in v])
        else:
            raise ValueError("Invalid features format")
        
        if cut_off is not None:
            if cut_off < 0:
                self.features = self.features[cut_off:, :]
                self.labels = self.labels[cut_off:]
            else:
                self.features = self.features[:cut_off, :]
                self.labels = self.labels[:cut_off]

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


def train_dnn_model(
    model: DNNMalwareDetector,
    train_loader: DataLoader,
    val_loader: DataLoader,
    epochs: int = 100,
    learning_rate: float = 0.01,
    device: str = "cpu",
    early_stopping_patience: int = 15,
    weight_decay: float = 1e-5,
    log_dir: str = "reports/runs",
    run_name: str = "",
    time_limit_in_seconds: int = 600,
    log_graph: bool = True,
    verbose_training: bool = True,
) -> Dict[str, List[float]]:
    """Train the malware detection model."""
    model = model.to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=learning_rate,
        weight_decay=weight_decay,
    )
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=0.5, patience=10
    )
    
    # Initialize TensorBoard writer with descriptive run name
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    if run_name == "":
        run_name = f"dnn_hls{model.layers[1]}_lr{learning_rate}_wd{weight_decay}_ep{epochs}"
    
    # Add unique identifier for parallel runs
    unique_id = f"{timestamp}_{run_name}"
    log_dir = Path(log_dir) / unique_id
    writer = SummaryWriter(log_dir=log_dir)
    logger.info(f"TensorBoard logging enabled. Logs will be saved to {log_dir}")
    logger.info(f"Run name: {run_name}")
    logger.info(f"Unique run ID: {unique_id}")
    
    # Add run identifier to TensorBoard
    writer.add_text('Run_Info', f"Run ID: {unique_id}", 0)
    
    # Log hyperparameters and model configuration to TensorBoard
    writer.add_text('Hyperparameters', f"""
    - Learning Rate: {learning_rate}
    - Weight Decay: {weight_decay}
    - Batch Size: {train_loader.batch_size}
    - Epochs: {epochs}
    - Time Limit: {time_limit_in_seconds} seconds
    - Device: {device}
    - Model Layers: {model.layers}
    - Total Parameters: {sum(p.numel() for p in model.parameters()):,}
    - Trainable Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}
    """, 0)
    
    # Log dataset information
    writer.add_text('Dataset Info', f"""
    - Training Samples: {len(train_loader.dataset)}
    - Validation Samples: {len(val_loader.dataset)}
    - Feature Count: {model.input_size}
    - Batch Size: {train_loader.batch_size}
    """, 0)

    # Log model graph to TensorBoard (only if requested and safe)
    if log_graph:
        try:
            # Use a more robust approach for graph logging during parallel training
            # Create a unique dummy input with a seed based on the run name to avoid conflicts
            import hashlib
            seed = int(hashlib.md5(run_name.encode()).hexdigest()[:8], 16) % 10000
            torch.manual_seed(seed)
            
            dummy_input = torch.randn(1, model.input_size).to(device)
            
            # Try to log the graph with better error handling
            try:
                writer.add_graph(model, dummy_input)
                logger.info(f"Successfully logged model graph to TensorBoard for {run_name}")
            except Exception as graph_error:
                if "Tracing failed sanity checks" in str(graph_error) or "Graphs differed across invocations" in str(graph_error):
                    logger.warning(f"Graph tracing conflict detected for {run_name} - skipping graph logging")
                    logger.info("This is normal during parallel training - each run will still log metrics and training curves")
                else:
                    raise graph_error
                
        except Exception as e:
            logger.warning(f"Failed to log model graph to TensorBoard for {run_name}: {e}")
            logger.info("This is normal during parallel training - graph logging will be skipped")
            
        # Reset seed to avoid affecting training
        torch.manual_seed(int(time.time()) % 10000)
    else:
        logger.info(f"Graph logging disabled for {run_name} - metrics and training curves will still be logged")

    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    best_val_loss = float("inf")
    patience_counter = 0

    logger.info(f"Starting training for {epochs} epochs on {device}")

    start_time = time.time()
    if time_limit_in_seconds is not None:
        logger.info(f"Training will stop after {time_limit_in_seconds} seconds")

    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for features, labels in train_loader:
            features, labels = features.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(features)
            # Squeeze outputs to match label dimensions for BCEWithLogitsLoss
            outputs_squeezed = outputs.squeeze()
            loss = criterion(outputs_squeezed, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            predictions = (outputs_squeezed > 0.5).float()
            train_correct += (predictions == labels).sum().item()
            train_total += labels.size(0)

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for features, labels in val_loader:
                features, labels = features.to(device), labels.to(device)
                outputs = model(features)
                # Squeeze outputs to match label dimensions for BCEWithLogitsLoss
                outputs_squeezed = outputs.squeeze()
                loss = criterion(outputs_squeezed, labels)
                val_loss += loss.item()

                predictions = (outputs_squeezed > 0.5).float()
                val_correct += (predictions == labels).sum().item()
                val_total += labels.size(0)

        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_accuracy = 100 * train_correct / train_total
        val_accuracy = 100 * val_correct / val_total

        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        train_accuracies.append(train_accuracy / 100)
        val_accuracies.append(val_accuracy / 100)

        # Log metrics to TensorBoard
        writer.add_scalar('Loss/Train', avg_train_loss, epoch)
        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)
        writer.add_scalar('Accuracy/Train', train_accuracy / 100, epoch)
        writer.add_scalar('Accuracy/Validation', val_accuracy / 100, epoch)
        writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)
        
        # Log additional useful metrics
        writer.add_scalar('Loss/Train_Validation_Diff', avg_train_loss - avg_val_loss, epoch)
        writer.add_scalar('Accuracy/Train_Validation_Diff', (train_accuracy - val_accuracy) / 100, epoch)
        writer.add_scalar('Training/Patience_Counter', patience_counter, epoch)
        writer.add_scalar('Training/Best_Val_Loss', best_val_loss, epoch)

        # Learning rate scheduling
        scheduler.step(avg_val_loss)

        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
        else:
            patience_counter += 1

        if verbose_training and epoch % 10 == 0:
            logger.info(
                f"Epoch {epoch:3d}: "
                f"Train Loss: {avg_train_loss:.4f} (Acc: {train_accuracy:.2f}%), "
                f"Val Loss: {avg_val_loss:.4f} (Acc: {val_accuracy:.2f}%)"
            )

        if time_limit_in_seconds is not None and time.time() - start_time > time_limit_in_seconds:
            logger.info(f"Time limit of {time_limit_in_seconds} seconds reached. Stopping training.")
            break

        # # Early stopping check
        # if patience_counter >= early_stopping_patience:
        #     logger.info(f"Early stopping triggered at epoch {epoch}")
        #     break

    # Log model parameters and gradients to TensorBoard
    for name, param in model.named_parameters():
        if param.grad is not None:
            writer.add_histogram(f'Gradients/{name}', param.grad, epoch)
        writer.add_histogram(f'Parameters/{name}', param, epoch)
    
    # Log final training summary
    final_epoch = len(train_losses) - 1
    writer.add_scalar('Summary/Final_Train_Loss', train_losses[-1] if train_losses else 0, final_epoch)
    writer.add_scalar('Summary/Final_Val_Loss', val_losses[-1] if val_losses else 0, final_epoch)
    writer.add_scalar('Summary/Final_Train_Accuracy', train_accuracies[-1] if train_accuracies else 0, final_epoch)
    writer.add_scalar('Summary/Final_Val_Accuracy', val_accuracies[-1] if val_accuracies else 0, final_epoch)
    writer.add_scalar('Summary/Best_Val_Loss', best_val_loss, final_epoch)
    writer.add_scalar('Summary/Total_Epochs', len(train_losses), final_epoch)
    writer.add_scalar('Summary/Training_Time_Seconds', time.time() - start_time, final_epoch)
    
    # Log training curves as line plots
    if train_losses:
        writer.add_scalar('Curves/Train_Loss_Curve', train_losses[-1], final_epoch)
        writer.add_scalar('Curves/Val_Loss_Curve', val_losses[-1], final_epoch)
        writer.add_scalar('Curves/Train_Accuracy_Curve', train_accuracies[-1] if train_accuracies else 0, final_epoch)
        writer.add_scalar('Curves/Val_Accuracy_Curve', val_accuracies[-1] if val_accuracies else 0, final_epoch)
    
    # Close TensorBoard writer
    writer.close()
    logger.info("Training completed")
    return {"train_losses": train_losses, "val_losses": val_losses, "train_accuracies": train_accuracies, "val_accuracies": val_accuracies}


def evaluate_dnn_model(
    model: DNNMalwareDetector, test_loader: DataLoader, device: str = "cpu"
) -> Dict[str, float]:
    """Evaluate the trained model."""
    model.eval()
    all_predictions = []
    all_labels = []
    test_loss = 0.0
    criterion = nn.BCEWithLogitsLoss()

    with torch.no_grad():
        for features, labels in test_loader:
            features, labels = features.to(device), labels.to(device)
            outputs = model(features)
            # Squeeze outputs to match label dimensions for BCEWithLogitsLoss
            outputs_squeezed = outputs.squeeze()
            loss = criterion(outputs_squeezed, labels)
            test_loss += loss.item()

            predictions = (outputs_squeezed > 0.5).float()
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate metrics
    from sklearn.metrics import (
        accuracy_score,
        f1_score,
        precision_score,
        recall_score,
        roc_auc_score,
    )

    accuracy = accuracy_score(all_labels, all_predictions)
    precision = precision_score(all_labels, all_predictions)
    recall = recall_score(all_labels, all_predictions)
    f1 = f1_score(all_labels, all_predictions)

    # For ROC AUC, we need the raw probabilities
    model.eval()
    all_probabilities = []
    all_labels_for_auc = []

    with torch.no_grad():
        for features, labels in test_loader:
            features, labels = features.to(device), labels.to(device)
            outputs = model(features)
            # Squeeze outputs to match label dimensions
            outputs_squeezed = outputs.squeeze()
            all_probabilities.extend(outputs_squeezed.cpu().numpy())
            all_labels_for_auc.extend(labels.cpu().numpy())

    try:
        auc = roc_auc_score(all_labels_for_auc, all_probabilities)
    except ValueError:
        auc = 0.0

    metrics = {
        "test_loss": test_loss / len(test_loader),
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "roc_auc": auc,
    }

    logger.info("Evaluation completed")
    for metric, value in metrics.items():
        logger.info(f"{metric}: {value:.4f}")

    return metrics
