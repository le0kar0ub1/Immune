"""Simple MLP for malware detection with training and evaluation."""

import logging
from pathlib import Path
from typing import Any, Dict, List, Optional

import torch
import torch.nn as nn
from torch.utils.data import DataLoader

logger = logging.getLogger(__name__)


class DNNMalwareDetector(nn.Module):
    """Simple fully connected MLP for malware detection."""

    def __init__(self, layers: Optional[List[int]] = None, dropout_rate: float = 0.5):
        super().__init__()

        if layers is None:
            layers = [345, 128, 64, 1]
        
        self.layers = layers
        self.input_size = layers[0]
        self.dropout_rate = dropout_rate

        modules: List[nn.Module] = []

        # Hidden layers: Linear + ReLU + Dropout
        for i in range(len(layers) - 2):
            modules.append(nn.Linear(layers[i], layers[i + 1]))
            modules.append(nn.ReLU())
            modules.append(nn.Dropout(dropout_rate))

        # Output layer
        modules.append(nn.Linear(layers[-2], layers[-1]))
        modules.append(nn.Sigmoid())

        # Use Sequential so the module is callable
        self.network = nn.Sequential(*modules)

        logger.info(f"Initialized DNNMalwareDetector with layers: {layers}")
        logger.info(f"Network: {self.network}")
        logger.info(f"Total parameters: {sum(p.numel() for p in self.parameters()):,}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

    def predict(self, x: torch.Tensor, threshold: float = 0.5) -> torch.Tensor:
        with torch.no_grad():
            probabilities = self.forward(x)
            return (probabilities > threshold).float()

    def get_feature_importance(self, x: torch.Tensor) -> torch.Tensor:
        x.requires_grad_(True)
        output = self.forward(x)
        output.backward(torch.ones_like(output))
        importance = torch.abs(x.grad)
        return importance

    def save_model(self, filepath: Path) -> None:
        torch.save(
            {
                "model_state_dict": self.state_dict(),
                "layers": self.layers,
                "dropout_rate": self.dropout_rate,
            },
            filepath,
        )
        logger.info(f"Model saved to {filepath}")

    @classmethod
    def load_model(cls, filepath: Path) -> "DNNMalwareDetector":
        checkpoint = torch.load(filepath, map_location="cpu")
        model = cls(layers=checkpoint["layers"], dropout_rate=checkpoint["dropout_rate"])
        model.load_state_dict(checkpoint["model_state_dict"])
        logger.info(f"Model loaded from {filepath}")
        return model


class MalwareDataset:
    """Dataset class for malware detection."""

    # from features.json
    def __init__(self, features: Dict[str, Dict[str, Any]]):
        v = features.values()
        self.features = torch.FloatTensor([feature["feature_array"] for feature in v])
        self.labels = torch.FloatTensor([feature["is_malware"] for feature in v])

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]


def train_dnn_model(
    model: DNNMalwareDetector,
    train_loader: DataLoader,
    val_loader: DataLoader,
    epochs: int = 100,
    learning_rate: float = 0.001,
    device: str = "cpu",
    early_stopping_patience: int = 15,
) -> Dict[str, List[float]]:
    """Train the malware detection model."""
    model = model.to(device)
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=0.5, patience=10
    )

    train_losses = []
    val_losses = []
    best_val_loss = float("inf")
    patience_counter = 0

    logger.info(f"Starting training for {epochs} epochs on {device}")

    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for features, labels in train_loader:
            features, labels = features.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, labels.unsqueeze(1))
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            predictions = (outputs > 0.5).float()
            train_correct += (predictions.squeeze() == labels).sum().item()
            train_total += labels.size(0)

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for features, labels in val_loader:
                features, labels = features.to(device), labels.to(device)
                outputs = model(features)
                loss = criterion(outputs, labels.unsqueeze(1))
                val_loss += loss.item()

                predictions = (outputs > 0.5).float()
                val_correct += (predictions.squeeze() == labels).sum().item()
                val_total += labels.size(0)

        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_accuracy = 100 * train_correct / train_total
        val_accuracy = 100 * val_correct / val_total

        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)

        # Learning rate scheduling
        scheduler.step(avg_val_loss)

        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
        else:
            patience_counter += 1

        if epoch % 10 == 0:
            logger.info(
                f"Epoch {epoch:3d}: "
                f"Train Loss: {avg_train_loss:.4f} (Acc: {train_accuracy:.2f}%), "
                f"Val Loss: {avg_val_loss:.4f} (Acc: {val_accuracy:.2f}%)"
            )

        # # Early stopping check
        # if patience_counter >= early_stopping_patience:
        #     logger.info(f"Early stopping triggered at epoch {epoch}")
        #     break

    logger.info("Training completed")
    return {"train_losses": train_losses, "val_losses": val_losses}


def evaluate_dnn_model(
    model: DNNMalwareDetector, test_loader: DataLoader, device: str = "cpu"
) -> Dict[str, float]:
    """Evaluate the trained model."""
    model.eval()
    all_predictions = []
    all_labels = []
    test_loss = 0.0
    criterion = nn.BCELoss()

    with torch.no_grad():
        for features, labels in test_loader:
            features, labels = features.to(device), labels.to(device)
            outputs = model(features)
            loss = criterion(outputs, labels.unsqueeze(1))
            test_loss += loss.item()

            predictions = (outputs > 0.5).float()
            all_predictions.extend(predictions.squeeze().cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate metrics
    from sklearn.metrics import (
        accuracy_score,
        f1_score,
        precision_score,
        recall_score,
        roc_auc_score,
    )

    accuracy = accuracy_score(all_labels, all_predictions)
    precision = precision_score(all_labels, all_predictions)
    recall = recall_score(all_labels, all_predictions)
    f1 = f1_score(all_labels, all_predictions)

    # For ROC AUC, we need the raw probabilities
    model.eval()
    all_probabilities = []
    all_labels_for_auc = []

    with torch.no_grad():
        for features, labels in test_loader:
            features, labels = features.to(device), labels.to(device)
            outputs = model(features)
            all_probabilities.extend(outputs.squeeze().cpu().numpy())
            all_labels_for_auc.extend(labels.cpu().numpy())

    try:
        auc = roc_auc_score(all_labels_for_auc, all_probabilities)
    except ValueError:
        auc = 0.0

    metrics = {
        "test_loss": test_loss / len(test_loader),
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "roc_auc": auc,
    }

    logger.info("Evaluation completed")
    for metric, value in metrics.items():
        logger.info(f"{metric}: {value:.4f}")

    return metrics
